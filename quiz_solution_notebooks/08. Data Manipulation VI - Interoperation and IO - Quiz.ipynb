{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1653908d",
   "metadata": {},
   "source": [
    "# 8. Data Manipulation VI - Interoperation and IO - Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a37bab",
   "metadata": {},
   "source": [
    "## 8.0. Import `polars` and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2da0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f2cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_column_rename_mapping = {\n",
    "    \"LocationID\": \"location_id\",\n",
    "    \"Borough\": \"borough\",\n",
    "    \"Zone\": \"zone\",\n",
    "}\n",
    "zones_df = (\n",
    "    pl.read_parquet(\"../data/taxi_zone_lookup.parquet\")\n",
    "    .rename(zone_column_rename_mapping)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb7a494-c830-47a0-94a5-fc4e303a92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_rides_column_rename_mapping = {\n",
    "    \"VendorID\": \"vendor_id\",\n",
    "    \"RatecodeID\": \"ratecode_id\",\n",
    "    \"PULocationID\": \"pu_location_id\",\n",
    "    \"DOLocationID\": \"do_location_id\",\n",
    "    \"Airport_fee\": \"airport_fee\",\n",
    "}\n",
    "\n",
    "rides_df = (\n",
    "    pl.read_parquet(\"../data/yellow_tripdata_2024-03.parquet\")\n",
    "    .rename(yellow_rides_column_rename_mapping)\n",
    "    .join(\n",
    "        zones_df.select(pl.all().name.prefix(\"pu_\")),\n",
    "        on=\"pu_location_id\",\n",
    "    )\n",
    "    .join(\n",
    "        zones_df.select(pl.all().name.prefix(\"do_\")),\n",
    "        on=\"do_location_id\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea04d2-31f8-45c4-b498-0c4771b09efe",
   "metadata": {},
   "source": [
    "## 8.1 Question 1: DataFrame Shape from List of Lists (Column Orientation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41b735-694f-488d-9da1-822f80f4365c",
   "metadata": {},
   "source": [
    "Given the data in the form of a list of lists, create a DataFrame using `pl.from_records()` with a column orientation. What is the shape of that DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b627f924-123b-4874-81c9-46522f05ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [\"bonnie\", \"ronnie\", \"donny\", \"johnny\", \"scrawny\"],\n",
    "    list(range(5)),\n",
    "    list(range(4, 9)),\n",
    "]\n",
    "result = (\n",
    "    #### YOUR CODE HERE\n",
    "    pl.from_records(data, orient=\"col\")\n",
    "    .shape\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a72c8-7976-41e3-b328-768559c5df23",
   "metadata": {},
   "source": [
    "1. (3, 5) - incorrect - make sure you're using the `\"col\"` orientation! See \"Interoperating DataFrames with Native Python Objects.\"\n",
    "2. (5, 3) - correct - Exactly! With column orientation, each list becomes a column of the DataFrame. See \"Interoperating DataFrames with Native Python Objects.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c2393-f5a7-4b54-80a1-8da1a8e638bc",
   "metadata": {},
   "source": [
    "## 8.2 Question 2: DataFrame Shape from List of Lists (Row Orientation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce1271-168a-40cd-9918-3621d14b83a3",
   "metadata": {},
   "source": [
    "Given the data in the form of a list of lists, create a DataFrame using `pl.from_records()` with a row orientation. What is the shape of that DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847e3bb6-5f2d-4847-98e7-c047c04f1ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [\"bonnie\", \"ronnie\", \"donny\", \"johnny\", \"scrawny\"],\n",
    "    list(range(5)),\n",
    "    list(range(4, 9)),\n",
    "]\n",
    "result = (\n",
    "    #### YOUR CODE HERE\n",
    "    pl.from_records(data, orient=\"row\")\n",
    "    .shape\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f996d4-fa5e-47c8-9708-1b8160509127",
   "metadata": {},
   "source": [
    "1. (3, 5) - correct - Exactly! With row orientation, each list becomes a row of the DataFrame. See \"Interoperating DataFrames with Native Python Objects.\"\n",
    "2. (5, 3) - incorrect - make sure you're using the `\"row\"` orientation! See \"Interoperating DataFrames with Native Python Objects.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48e4e6-a403-47b3-8b36-2883042ce5fa",
   "metadata": {},
   "source": [
    "## 8.3 Question 3: Datatype Changes After CSV Write and Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a57e8-ecdb-45ae-9639-4a9811556904",
   "metadata": {},
   "source": [
    "Save out the DataFrame to a CSV file with `.write_csv()` to `\"./temp_file.csv\"`. Then, read it back in with `.read_csv()`. Have the datatypes changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d461f5-c61a-4d56-962e-e945776a89e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ u8  │\n",
      "╞═════╪═════╪═════╡\n",
      "└─────┴─────┴─────┘\n",
      "shape: (0, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ i64 │\n",
      "╞═════╪═════╪═════╡\n",
      "└─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "save_path = \"temp_file.csv\"\n",
    "df = pl.DataFrame([\n",
    "    pl.Series(name=\"a\", values=500 * [\"derek\", \"carole\"]),\n",
    "    pl.Series(name=\"b\", values=list(range(1000))),\n",
    "    pl.Series(name=\"c\", values=[i % 4 for i in list(range(1000))], dtype=pl.UInt8),\n",
    "])\n",
    "print(df.head(0))  # See schema before saving.\n",
    "#### YOUR CODE HERE\n",
    "df.write_csv(save_path)\n",
    "print(pl.read_csv(save_path).head(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802eeb1-db18-4e2a-813c-e72a36550be9",
   "metadata": {},
   "source": [
    "1. Yes - correct - Exactly! CSV files don't store datatypes, so polars has to infer them upon loading, usually choosing `i64` for integers. See \"DataFrame IO.\"\n",
    "2. No - incorrect - make sure you're not using any extra arguments to `.read_csv()` and letting polars infer the datatypes. See \"DataFrame IO.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1cb416-535f-44f9-b4dd-a92cd01b0917",
   "metadata": {},
   "source": [
    "## 8.4 Question 4: Datatype Changes After NDJSON Write and Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627425b8-1735-46a5-8382-d56e181973de",
   "metadata": {},
   "source": [
    "Save out the DataFrame to an NDJSON file with `.write_ndjson()` to `\"./temp_file.njson\"`. Then, read it back in with `.read_ndjson()`. Have the datatypes changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9aaa53b-df41-4a2e-a994-d6dcbebdaf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ u8  │\n",
      "╞═════╪═════╪═════╡\n",
      "└─────┴─────┴─────┘\n",
      "shape: (0, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ i64 │\n",
      "╞═════╪═════╪═════╡\n",
      "└─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "save_path = \"temp_file.njson\"\n",
    "df = pl.DataFrame([\n",
    "    pl.Series(name=\"a\", values=500 * [\"derek\", \"carole\"]),\n",
    "    pl.Series(name=\"b\", values=list(range(1000))),\n",
    "    pl.Series(name=\"c\", values=[i % 4 for i in list(range(1000))], dtype=pl.UInt8),\n",
    "])\n",
    "print(df.head(0))  # See schema before saving.\n",
    "#### YOUR CODE HERE\n",
    "df.write_ndjson(save_path)\n",
    "print(pl.read_ndjson(save_path).head(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ab82f-ba55-415d-ba58-80179d900533",
   "metadata": {},
   "source": [
    "1. Yes - correct - Exactly! NDJSON files don't store datatypes, so polars has to infer them upon loading, usually choosing `i64` for integers. See \"DataFrame IO.\"\n",
    "2. No - incorrect - make sure you're not using any extra arguments to `.read_ndjson()` and letting polars infer the datatypes. See \"DataFrame IO.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233613f5-72ca-4dd2-9740-550edabbd8ad",
   "metadata": {},
   "source": [
    "## 8.5 Question 5: Datatype Changes After Parquet Write and Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84fb22-536b-42ad-ae0d-886582374d18",
   "metadata": {},
   "source": [
    "Save out the DataFrame to a Parquet file with `.write_parquet()` to `\"./temp_file.parquet\"`. Then, read it back in with `.read_parquet()`. Have the datatypes changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93a60e26-889c-4d75-8f37-8e3eb9e4b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ u8  │\n",
      "╞═════╪═════╪═════╡\n",
      "└─────┴─────┴─────┘\n",
      "shape: (0, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ u8  │\n",
      "╞═════╪═════╪═════╡\n",
      "└─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "save_path = \"temp_file.parquet\"\n",
    "df = pl.DataFrame([\n",
    "    pl.Series(name=\"a\", values=500 * [\"derek\", \"carole\"]),\n",
    "    pl.Series(name=\"b\", values=list(range(1000))),\n",
    "    pl.Series(name=\"c\", values=[i % 4 for i in list(range(1000))], dtype=pl.UInt8),\n",
    "])\n",
    "print(df.head(0))  # See schema before saving.\n",
    "#### YOUR CODE HERE\n",
    "df.write_parquet(save_path)\n",
    "print(pl.read_parquet(save_path).head(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6633b0f-1e89-4655-963b-4f96a1cd7d85",
   "metadata": {},
   "source": [
    "1. Yes - incorrect - make sure you're not transforming the DataFrame before saving with `.write_parquet()`. See \"DataFrame IO.\"\n",
    "2. No - correct - Exactly! Parquet stores schema with the data, so it loads back exactly as it was saved. See \"DataFrame IO.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
